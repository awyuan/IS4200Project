{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af84995d",
   "metadata": {},
   "source": [
    "Todos: \n",
    "- Encoding: use VSM* to convert text from pdfs into vectors (unanswered: how much of the document can we feed before word2vec explodes?) *-- realized word2vec isn't what you use for document to vector, it'd need to be a vector space model \n",
    "- Models: use a SOTA transformer model? (unanswered: do we need to fine tune or can we use a previously created model as is? If fine tuning, what is our training set / testing set and do we have enough data?)\n",
    "- Search/Ranking: Not that difficult once the model can produce predictions (use softmax/logit scores as relevancy score, can naively search pdf for location of citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b7f3feaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from collections import defaultdict\n",
    "import re\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "614fac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdfs():\n",
    "    source_pdfs = [] # single array of abstract text for sources\n",
    "    cited_pdfs = defaultdict(lambda: defaultdict(lambda: [])) # source paper --> {relevant: [], nonrelevant: []}\n",
    "    initial_path = './data/'\n",
    "    papers = ['paper1', 'paper2', 'paper3', 'paper4', 'paper5', 'paper6', 'paper7']\n",
    "    for paper in papers:\n",
    "        source_paper_path = join(initial_path, paper)\n",
    "        pdfs = [join(source_paper_path, f) for f in listdir(source_paper_path) if isfile(join(source_paper_path, f))]\n",
    "        source_pdfs.append(pdfs[0])\n",
    "        source_paper_path += '/Cited/'\n",
    "        relevance = ['Relevant', 'Less Relevant']\n",
    "        for rel in relevance:\n",
    "            cited_paper_path = source_paper_path + rel\n",
    "            cited_pdf_paths = [join(cited_paper_path, f) for f in listdir(cited_paper_path) if isfile(join(cited_paper_path, f))]\n",
    "            cited_pdfs[paper][rel] = cited_pdf_paths\n",
    "    return source_pdfs, cited_pdfs\n",
    "\n",
    "source_pdf_paths, cited_pdf_paths = get_pdfs()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4518a8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_page_text(input_list, path):\n",
    "    reader = PdfReader(path)\n",
    "    for page in reader.pages:\n",
    "        text = page.extract_text()\n",
    "        if re.search('abstract', text, flags=re.I):\n",
    "            input_list.append(text)\n",
    "            return\n",
    "    input_list.append('none')\n",
    "\n",
    "def get_abstract_page(source_pdf_paths, cited_pdf_paths):\n",
    "    source_abstracts = [] # single array of abstract text for sources\n",
    "    cited_abstracts = defaultdict(lambda: defaultdict(lambda: [])) # source paper --> {relevant: [], nonrelevant: []}\n",
    "    for ppath in source_pdf_paths:\n",
    "        add_page_text(source_abstracts, ppath)\n",
    "    papers = ['paper1', 'paper2', 'paper3', 'paper4', 'paper5', 'paper6', 'paper7']\n",
    "    for paper in papers:\n",
    "        relevance = ['Relevant', 'Less Relevant']\n",
    "        for rel in relevance:\n",
    "            page_text_array = []\n",
    "            for ppath in cited_pdf_paths[paper][rel]:\n",
    "                add_page_text(page_text_array, ppath)\n",
    "            cited_abstracts[paper][rel] = page_text_array\n",
    "    return source_abstracts, cited_abstracts\n",
    "        \n",
    "source_abstracts, cited_abstracts = get_abstract_page(source_pdf_paths, cited_pdf_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f4c4bf14",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = source_abstracts[0].replace(\"\\n\", \" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b865204d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'poison frogs! targeted clean-label poisoning attacks on neural networks ali shafahi university of maryland ashafahi@cs.umd.eduw. ronny huang university of maryland wrhuang@umd.edu mahyar najibi university of maryland najibi@cs.umd.eduoctavian suciu university of maryland osuciu@umiacs.umd.educhristoph studer cornell university studer@cornell.edu tudor dumitras university of maryland tudor@umiacs.umd.edutom goldstein university of maryland tomg@cs.umd.edu abstract data poisoning is an attack on machine learning models wherein the attacker adds examples to the training set to manipulate the behavior of the model at test time. this paper explores poisoning attacks on neural nets. the proposed attacks use \"clean-labels\"; they don\\'t require the attacker to have any control over the labeling of training data. they are also targeted; they control the behavior of the classifier on a specific test instance without degrading overall classifier performance. for example, an attacker could add a seemingly innocuous image (that is properly labeled) to a training set for a face recognition engine, and control the identity of a chosen person at test time. because the attacker does not need to control the labeling function, poisons could be entered into the training set simply by leaving them on the web and waiting for them to be scraped by a data collection bot. we present an optimization-based method for crafting poisons, and show that just one single poison image can control classifier behavior when transfer learning is used. for full end-to-end training, we present a \"watermarking\" strategy that makes poisoning reliable using multiple ( 50) poisoned training instances. we demonstrate our method by generating poisoned frog images from the cifar dataset and using them to manipulate image classifiers. 1 introduction before deep learning algorithms can be deployed in high stakes, security-critical applications, their robustness against adversarial attacks must be put to the test. the existence of adversarial examples in deep neural networks (dnns) has triggered debates on how secure these classifiers are [szegedy et al., 2013, goodfellow et al., 2015, biggio et al., 2013]. adversarial examples fall within a category of attacks called evasion attacks . evasion attacks happen at test time a clean target instance is modified to avoid detection by a classifier, or spur misclassification. however, these attacks do not map to certain realistic scenarios in which the attacker cannot control test time data. for example, consider a retailer aiming to mark a competitor\\'s email as spam through an ml-based spam filter. evasion attacks are not applicable because the attacker cannot modify the victim emails. similarly, authors contributed equally. 32nd conference on neural information processing systems (nips 2018), montreal, canada.arxiv:1804.00792v2 [cs.lg] 10 nov 2018'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean(test,\n",
    "    fix_unicode=True,               # fix various unicode errors\n",
    "    to_ascii=True,                  # transliterate to closest ASCII representation\n",
    "    lower=True,                     # lowercase text\n",
    "    no_line_breaks=False,           # fully strip line breaks as opposed to only normalizing them\n",
    "    no_urls=False,                  # replace all URLs with a special token\n",
    "    no_emails=False,                # replace all email addresses with a special token\n",
    "    no_phone_numbers=False,         # replace all phone numbers with a special token\n",
    "    no_numbers=False,               # replace all numbers with a special token\n",
    "    no_digits=False,                # replace all digits with a special token\n",
    "    no_currency_symbols=False,      # replace all currency symbols with a special token\n",
    "    no_punct=False,                 # remove punctuations\n",
    "    replace_with_punct=\"\",          # instead of removing punctuations you may replace them\n",
    "    replace_with_url=\"<URL>\",\n",
    "    replace_with_email=\"<EMAIL>\",\n",
    "    replace_with_phone_number=\"<PHONE>\",\n",
    "    replace_with_number=\"<NUMBER>\",\n",
    "    replace_with_digit=\"0\",\n",
    "    replace_with_currency_symbol=\"<CUR>\",\n",
    "    lang=\"en\"                       # set to 'de' for German special handling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42568289",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "06857816d295f49859cc9b744cb5307f357aa28072ae1f3fa176dda7f6176408"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
